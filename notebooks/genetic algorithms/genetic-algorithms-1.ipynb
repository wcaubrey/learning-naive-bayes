{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T00:24:50.611604300Z",
     "start_time": "2026-02-08T00:24:32.239252900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1: Best Accuracy = 0.7692\n",
      "Generation 2: Best Accuracy = 0.8022\n",
      "Generation 3: Best Accuracy = 0.8352\n",
      "Generation 4: Best Accuracy = 0.8242\n",
      "Generation 5: Best Accuracy = 0.8352\n",
      "Generation 6: Best Accuracy = 0.8132\n",
      "Generation 7: Best Accuracy = 0.8242\n",
      "Generation 8: Best Accuracy = 0.8352\n",
      "Generation 9: Best Accuracy = 0.8242\n",
      "Generation 10: Best Accuracy = 0.8242\n",
      "Generation 11: Best Accuracy = 0.8242\n",
      "Generation 12: Best Accuracy = 0.8242\n",
      "Generation 13: Best Accuracy = 0.8022\n",
      "Generation 14: Best Accuracy = 0.8022\n",
      "Generation 15: Best Accuracy = 0.8352\n",
      "Generation 16: Best Accuracy = 0.8462\n",
      "Generation 17: Best Accuracy = 0.8022\n",
      "Generation 18: Best Accuracy = 0.8242\n",
      "Generation 19: Best Accuracy = 0.8022\n",
      "Generation 20: Best Accuracy = 0.8462\n",
      "Generation 21: Best Accuracy = 0.8242\n",
      "Generation 22: Best Accuracy = 0.8242\n",
      "Generation 23: Best Accuracy = 0.8242\n",
      "Generation 24: Best Accuracy = 0.8242\n",
      "Generation 25: Best Accuracy = 0.8242\n",
      "Generation 26: Best Accuracy = 0.8352\n",
      "Generation 27: Best Accuracy = 0.8022\n",
      "Generation 28: Best Accuracy = 0.8132\n",
      "Generation 29: Best Accuracy = 0.8132\n",
      "Generation 30: Best Accuracy = 0.8352\n",
      "Generation 31: Best Accuracy = 0.8462\n",
      "Generation 32: Best Accuracy = 0.8352\n",
      "Generation 33: Best Accuracy = 0.7912\n",
      "Generation 34: Best Accuracy = 0.8242\n",
      "Generation 35: Best Accuracy = 0.8132\n",
      "Generation 36: Best Accuracy = 0.8132\n",
      "Generation 37: Best Accuracy = 0.8132\n",
      "Generation 38: Best Accuracy = 0.8242\n",
      "Generation 39: Best Accuracy = 0.8352\n",
      "Generation 40: Best Accuracy = 0.8022\n",
      "Generation 41: Best Accuracy = 0.8242\n",
      "Generation 42: Best Accuracy = 0.8132\n",
      "Generation 43: Best Accuracy = 0.8352\n",
      "Generation 44: Best Accuracy = 0.8022\n",
      "Generation 45: Best Accuracy = 0.8132\n",
      "Generation 46: Best Accuracy = 0.8132\n",
      "Generation 47: Best Accuracy = 0.8352\n",
      "Generation 48: Best Accuracy = 0.8242\n",
      "Generation 49: Best Accuracy = 0.8352\n",
      "Generation 50: Best Accuracy = 0.8352\n",
      "\n",
      "Best feature subset:\n",
      "['age', 'sex', 'cp', 'trestbps', 'chol', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
      "Generation 50: Best Accuracy = 0.8352\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\"\"\"\n",
    "Load the dataset.\n",
    "X will have the features.\n",
    "Y will have the label we want to predict.\n",
    "\"\"\"\n",
    "df = pd.read_csv(\"../../data/heartdiseasetrain/heart.csv\")\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "num_features = X.shape[1]\n",
    "\n",
    "\"\"\"\n",
    "GA Tuning Parameters:\n",
    "- POP_SIZE: Number of candidate solutions (feature subsets) in each generation.\n",
    "- NUM_GENERATIONS: How many iterations the GA will run to evolve better feature subsets.\n",
    "- MUTATION_RATE: Probability of randomly flipping a bit in the feature mask to maintain diversity.\n",
    "\"\"\"\n",
    "POP_SIZE = 30\n",
    "NUM_GENERATIONS = 50\n",
    "MUTATION_RATE = 0.1\n",
    "\n",
    "\"\"\"\n",
    "This function is the heart of the GA.\n",
    "The selected variable is a list of indices of features that are included in the current subset (where bit == 1).\n",
    "We split the data into training and testing sets using only the selected features, train a Decision Tree classifier, and return the accuracy on the test set as the fitness score. If no features are selected, we return a fitness of 0 to avoid evaluating an empty feature set.\n",
    "\"\"\"\n",
    "def fitness(individual):\n",
    "    selected = [i for i, bit in enumerate(individual) if bit == 1]\n",
    "    if len(selected) == 0:\n",
    "        return 0  # avoid empty feature sets\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X.iloc[:, selected], y, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return accuracy_score(y_test, preds)\n",
    "\n",
    "\"\"\"\n",
    "This function creates a population of random features.\n",
    "\"\"\"\n",
    "def init_population():\n",
    "    return np.random.randint(0, 2, (POP_SIZE, num_features))\n",
    "\n",
    "\"\"\"\n",
    "Pick two individuals at random from the population and return the one with the higher fitness.\n",
    "This is what makes the GA evolve to the better solution.\n",
    "\"\"\"\n",
    "def select(pop, fitnesses):\n",
    "    idx1, idx2 = np.random.randint(0, POP_SIZE, 2)\n",
    "    return pop[idx1] if fitnesses[idx1] > fitnesses[idx2] else pop[idx2]\n",
    "\n",
    "\"\"\"\n",
    "Combine two parents by picking a random location to split the features, then take the 'left'\n",
    "side features of one and combine with the 'right' side of the other.\n",
    "\"\"\"\n",
    "def crossover(parent1, parent2):\n",
    "    point = np.random.randint(1, num_features - 1)\n",
    "    child = np.concatenate([parent1[:point], parent2[point:]])\n",
    "    return child\n",
    "\n",
    "\"\"\"\n",
    "This mutates the given indivual by randomly flipping bits with a certain probability (MUTATION_RATE). This helps maintain diversity in the population and allows the GA to explore new feature combinations that may not be reached through selection and crossover alone.\n",
    "\"\"\"\n",
    "def mutate(individual):\n",
    "    for i in range(num_features):\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            individual[i] = 1 - individual[i]\n",
    "    return individual\n",
    "\n",
    "\"\"\"\n",
    "Run the GA\n",
    "\"\"\"\n",
    "population = init_population()\n",
    "\n",
    "for gen in range(NUM_GENERATIONS):\n",
    "    fitnesses = np.array([fitness(ind) for ind in population])\n",
    "\n",
    "    new_population = []\n",
    "    for _ in range(POP_SIZE):\n",
    "        parent1 = select(population, fitnesses)\n",
    "        parent2 = select(population, fitnesses)\n",
    "        child = crossover(parent1, parent2)\n",
    "        child = mutate(child)\n",
    "        new_population.append(child)\n",
    "\n",
    "    population = np.array(new_population)\n",
    "\n",
    "    best_idx = np.argmax(fitnesses)\n",
    "    print(f\"Generation {gen+1}: Best Accuracy = {fitnesses[best_idx]:.4f}\")\n",
    "\n",
    "\"\"\"\n",
    "Show the best features identified by GA.\n",
    "\"\"\"\n",
    "best_individual = population[np.argmax([fitness(ind) for ind in population])]\n",
    "selected_features = [col for col, bit in zip(X.columns, best_individual) if bit == 1]\n",
    "\n",
    "print(\"\\nBest feature subset:\")\n",
    "print(selected_features)\n",
    "print(f\"Generation {gen+1}: Best Accuracy = {fitnesses[best_idx]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
